{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data - run prep_exp.ipynb first\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"temp.pkl\",\"rb\")\n",
    "data = pickle.load(pickle_in)\n",
    "\n",
    "# # If it's not there, do the following:\n",
    "# import sys\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from str2bool import str2bool\n",
    "# from rpy2.robjects.packages import STAP\n",
    "# import rpy2.robjects as robjects\n",
    "# from rpy2.robjects import pandas2ri, numpy2ri\n",
    "# from rpy2.robjects.lib.dplyr import DataFrame\n",
    "# from rpy2.robjects.packages import importr\n",
    "\n",
    "# pandas2ri.activate()\n",
    "# numpy2ri.activate()\n",
    "\n",
    "# # Some temporary arguments for testing\n",
    "# include_lab = str2bool(\"T\")  # Include lab features?\n",
    "# include_ethdon = str2bool(\"T\")  # Include ethnicity + donor details?\n",
    "# lag = int(\"1\")  # Number of lag variables\n",
    "# eq_train_ratio = str2bool(\"T\")  # Train on equal case:control ratio?\n",
    "# __file__ = '/h/angeliney/projects/SRTR/prep_exp.py'\n",
    "# visit_type = \"first\"\n",
    "# output = \"temp\"\n",
    "# post2000 = True\n",
    "\n",
    "# # Get features based on these inputs\n",
    "# with open(os.path.join(os.path.dirname(__file__), 'features.R'), 'r') as f:\n",
    "#     string = f.read()\n",
    "# features_file = STAP(string, \"features\")\n",
    "# features_to_use = features_file.features.rx2(\"clin\")\n",
    "# if include_lab:\n",
    "#     features_to_use = features_to_use + features_file.features.rx2(\"lab\")\n",
    "\n",
    "# if include_ethdon:\n",
    "#     features_to_use = features_to_use + features_file.features.rx2(\"eth\") + features_file.features.rx2(\"don\")\n",
    "\n",
    "# timedep_cols = np.intersect1d(features_to_use, features_file.timedep_features)\n",
    "# cov_cols = np.setdiff1d(features_to_use, timedep_cols)\n",
    "\n",
    "# if eq_train_ratio:\n",
    "#     eq_cases_train_cols = np.array([\"TRR_ID\", \"is_diab\"])\n",
    "# else:\n",
    "#     eq_cases_train_cols = np.array()\n",
    "    \n",
    "# # Read RDS files (load data table)\n",
    "# readRDS = robjects.r['readRDS']\n",
    "# tx_li_study = readRDS(os.path.join(os.path.dirname(__file__), 'tx_li_formatted.rds'))\n",
    "# txf_li_study = readRDS(os.path.join(os.path.dirname(__file__), 'txf_li_formatted.rds'))\n",
    "\n",
    "# # Merge them\n",
    "# with open(os.path.join(os.path.dirname(__file__), 'functions.R'), 'r') as f:\n",
    "#     string = f.read()\n",
    "# functions = STAP(string, \"functions\")\n",
    "\n",
    "# merged = functions.combine_tx_txf(tx_li_study, txf_li_study, np.setdiff1d(cov_cols, \"age\"), timedep_cols, lag)\n",
    "\n",
    "# df = pandas2ri.ri2py_dataframe(DataFrame(merged).filter('time_next_followup > time_since_transplant'))\n",
    "\n",
    "# #Prep data for model training\n",
    "# cols = np.concatenate((timedep_cols, cov_cols))\n",
    "# if lag > 0:\n",
    "#     for l in range(1,  lag + 1):\n",
    "#         cols = np.append(cols, list(map(lambda x: '{}_{}'.format(x, l), timedep_cols)))\n",
    "\n",
    "# subset_cols = np.concatenate((['transplant_year', 'TRR_ID', 'age'], cols, ['is_diab', 'time_since_transplant',\n",
    "#                                                                    'time_next_followup', 'time_to_diab',\n",
    "#                                                                    'diab_time_since_tx', 'diab_in_1_year',\n",
    "#                                                                    'diab_now']))\n",
    "# df = df.dropna(subset=subset_cols)\n",
    "# df_test = df[(df.transplant_year.astype(int) >= 2011) & (df.time_to_diab >= 0)]\n",
    "# df_nontest = df[(df.transplant_year.astype(int) < 2011) & (df.time_to_diab >= 0)]\n",
    "\n",
    "# num_folds = 5\n",
    "# nontest_y = df_nontest.drop_duplicates(subset=['TRR_ID', 'is_diab']).is_diab\n",
    "# caret = importr('caret')\n",
    "# folds = caret.createFolds(nontest_y, num_folds, False)\n",
    "\n",
    "# data = {'test': df_test, 'train': df_nontest, 'cols': cols, 'eq_cases_train_cols': eq_cases_train_cols,\n",
    "#             'folds': folds}\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# # Save data in case kernel got restarted\n",
    "# pickle.dump(data, open(\"temp.pkl\", \"wb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/angeliney/miniconda2/lib/python2.7/site-packages/sklearn/utils/__init__.py:12: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/h/angeliney/miniconda2/lib/python2.7/site-packages/sklearn/utils/extmath.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/h/angeliney/miniconda2/lib/python2.7/site-packages/sklearn/utils/extmath.py:25: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sparsefuncs_fast import csr_row_norms\n",
      "/h/angeliney/miniconda2/lib/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:25: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/h/angeliney/miniconda2/lib/python2.7/site-packages/sklearn/metrics/pairwise.py:31: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n",
      "/h/angeliney/miniconda2/lib/python2.7/site-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._criterion import Criterion\n",
      "/h/angeliney/miniconda2/lib/python2.7/site-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ball_tree import BallTree\n",
      "/h/angeliney/miniconda2/lib/python2.7/site-packages/sklearn/neighbors/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .kd_tree import KDTree\n",
      "/h/angeliney/miniconda2/lib/python2.7/site-packages/sklearn/utils/random.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._random import sample_without_replacement\n",
      "/h/angeliney/miniconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.py:34: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    }
   ],
   "source": [
    "# Try MERF\n",
    "import numpy as np\n",
    "import pandas\n",
    "import sys\n",
    "import pickle\n",
    "from merf import MERF\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from str2bool import str2bool\n",
    "from functions import prep_exp, filter_train_by_visit\n",
    "\n",
    "cols = np.append(data['cols'], 'time_since_transplant')\n",
    "nontest_ids = data['train'].drop_duplicates(subset=['TRR_ID', 'is_diab']).TRR_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pandas.DataFrame()\n",
    "for i in range(num_folds+1):\n",
    "    if i > 0:\n",
    "        train_ids = nontest_ids[np.array(data['folds']) != i]\n",
    "        val_ids = np.setdiff1d(nontest_ids, train_ids)\n",
    "        test = data['train'][data['train']['TRR_ID'].isin(val_ids)]\n",
    "    else:\n",
    "        train_ids = nontest_ids\n",
    "        test = data['test']\n",
    "\n",
    "    train = filter_train_by_visit(visit_type, data['train'][data['train'].TRR_ID.isin(train_ids)])\n",
    "\n",
    "    merf = MERF(n_estimators=100, gll_early_stop_threshold=0.001, max_iterations=2)\n",
    "    merf.fit(train[cols], pandas.DataFrame(np.ones((train.shape[0], 1))), train.TRR_ID, train.diab_in_1_year)\n",
    "    train_y_hat = merf.predict(train[cols], pandas.DataFrame(np.ones((train.shape[0], 1))), train.TRR_ID)\n",
    "    test_y_hat = merf.predict(test[cols], pandas.DataFrame(np.ones((test.shape[0], 1))), test.TRR_ID)\n",
    "\n",
    "    train_auroc = roc_auc_score(train.diab_in_1_year, train_y_hat)\n",
    "    test_auroc = roc_auc_score(test.diab_in_1_year, test_y_hat)\n",
    "\n",
    "    if i == 0:\n",
    "        perf = {'model': merf, 'train_auroc': train_auroc, 'test_auroc': test_auroc,\n",
    "                'train_nrow': train.shape[0], 'test_nrow': test.shape[0]}\n",
    "        pickle.dump(perf, open('{}_perf.pkl'.format(output), 'wb'))\n",
    "\n",
    "    print('{},{},{},{},{}'.format(i, train_auroc, test_auroc, train.shape[0], test.shape[0]))\n",
    "    result.append(pandas.DataFrame({'train_auroc': train_auroc, 'test_auroc': test_auroc,\n",
    "                                    'train_nrow': train.shape[0], 'test_nrow': test.shape[0]}, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "if i > 0:\n",
    "    train_ids = nontest_ids[np.array(data['folds']) != i]\n",
    "    val_ids = np.setdiff1d(nontest_ids, train_ids)\n",
    "    test = data['train'][data['train']['TRR_ID'].isin(val_ids)]\n",
    "else:\n",
    "    train_ids = nontest_ids\n",
    "    test = data['test']\n",
    "\n",
    "train = filter_train_by_visit(\"all\", data['train'][data['train'].TRR_ID.isin(train_ids)])\n",
    "\n",
    "merf = MERF(n_estimators=100, gll_early_stop_threshold=0.001, max_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "i=1\n",
    "if i > 0:\n",
    "    train_ids = nontest_ids[np.array(data['folds']) != i]\n",
    "    val_ids = np.setdiff1d(nontest_ids, train_ids)\n",
    "    test = data['train'][data['train']['TRR_ID'].isin(val_ids)]\n",
    "else:\n",
    "    train_ids = nontest_ids\n",
    "    test = data['test']\n",
    "\n",
    "train = filter_train_by_visit(\"all\", data['train'][data['train'].TRR_ID.isin(train_ids)])\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "model.fit(train[cols], train.diab_in_1_year)\n",
    "train_y_hat = model.predict(train[cols])\n",
    "test_y_hat = model.predict(test[cols])\n",
    "\n",
    "train_auroc = roc_auc_score(train.diab_in_1_year, train_y_hat)\n",
    "test_auroc = roc_auc_score(test.diab_in_1_year, test_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
